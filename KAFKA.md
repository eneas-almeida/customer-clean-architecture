# Kafka

Documenta√ß√£o:

-   [kafjajs](https://kafka.js.org/docs/getting-started)
-   [Cofluent examples](https://github.com/confluentinc/cp-docker-images/tree/5.3.3-post/examples)

## Perguntas

-   Onde salvar os eventos?
-   Como recuperar de forma r√°pida e simples de forma que o feedback entre um processo e outro ou memos entre um sistema e outro possa acontecer de forma flu√≠da e em tempo real?
-   Como escalar?
-   Como ter resili√™ncia e alta disponibilidade?

## Vantagens

-   Desenvolvido em Java;
-   Opensource;
-   Alta capacidade de processar requisi√ß√µes;
-   Lat√™ncia extramamente baixa (2ms);
-   Escal√°vel;
-   Armazenamento, as mensagens ficam guardadas, banco de dados otimizado;
-   Alta disponibilidade;
-   Se conecta com quase tudo, existe drivers para v√°rias tecnologias, existem muitas bibliotecas prontas.

## Quem usa?

-   Linkedin;
-   Netflix;
-   Uber;
-   Twitter;
-   Dropbox;
-   Spotify;
-   PayPal;
-   Bancos.

## Como funciona?

-   O produtor envia uma mensagem para o Kafka, que fica armazenado em um broker, que possui um banco de dados pr√≥prio, o consumidor por sua vez, realiza a leitura das mensagens nos brokers.

<img src="./media/kafka/kafka-1.png" />

## T√≥picos

S√£o canais de comunica√ß√µes respons√°veis por receber e disponibilizar os dados enviados para o Kafka.

<img src="./media/kafka/kafka-2.png" />

Os t√≥picos podem ser lidos por multiplos sistemas, diferentemente do RabbitMQ que ao ler um t√≥pico, a mensagem √© perdida, n√£o podendo ser lido por multiplos sistemas.

<img src="./media/kafka/kafka-3.png" />

Quando o produtor envia uma mensagem atrav√©s de um t√≥pico, um id (offset) √© atribuido a mensagem e vai sendo salva em disco de forma enfileirada, dessa forma, a mensagem pode ser reprocesada, exemplo, voltar no offset 2 e reprocessar.

### Anatomia de uma mensagem

A mensagem √© composta por 4 partes:

-   **Cabe√ßalho:** metadados
-   **Key:** contexto da mensagem, garante a ordem de entrega da mensagem
-   **Value:** payload, o pr√≥prio JSON
-   **Timestamp**

<img src="./media/kafka/kafka-4.png" />

## Parti√ß√µes

Como demonstrado abaixo, cada t√≥pico pode ter uma ou mais parti√ß√µes, garantindo a distribui√ß√£o e resili√™ncia dos dados.

<img src="./media/kafka/kafka-5.png" />

Quando uma mensagem √© enviada, atrav√©s de um t√≥pico, o destino √© uma das 3 parti√ß√µes, de acordo com o algoritmo do Kafka (round-robin), como ilustrada na imagem acima, isso garante diversas estrat√©gias para o cosumidor, diminuindo o risco da mensagem ser entregue e aumentando a quantidade de consumidores.

**Exemplo:** uma hip√≥tese de envio de 1500 mensangens, √© poss√≠vel enviar 500 mensagens para a parti√ß√£o 1, 500 para parti√ß√£o 2 e 500 para parti√ß√£o 3, fica mais r√°pido a leitura pelo consumidor em determinadas parti√ß√µes.

### Parti√ß√µes distribu√≠das

<img src="./media/kafka/kafka-7.png" />

As parti√ß√µes distribu√≠das garantem resili√™ncia, onde, caso um broker caia, as outras parti√ß√µes ter√£o os backups das mensagens em outros brokers.

-   **Comum:** 2 replicators.
-   **Casos cr√≠ticos:** 3 replicators.

### Parti√ß√£o l√≠der

Como ilustrado na imagem a baixo, cada broker tem uma parti√ß√£o l√≠der, dessa forma, necessariamente, o cosumidor ler a parti√ß√£o l√≠der.

<img src="./media/kafka/kafka-8-1.png" />

Quando um broker cai, o gerenciador do Kafka elege uma parti√ß√£o l√≠der, como demonstado na imagem abaixo.

<img src="./media/kafka/kafka-8-2.png" />

## Keys

<img src="./media/kafka/kafka-6.png" />

As **keys garantem as ordens de entregas**, alocando as mensagens em uma mesma parti√ß√£o, entretanto se n√£o tiver a necessidade de uma leitura ordenada, apenas basta n√£o informar uma key, que o Kafka ir√° definir atrav√©s do seu algoritmo, em qual parti√ß√£o ir√° ficar aquela mensagem.

## Garantia de entregas

### Producer

<img src="./media/kafka/kafka-9-1.png" />

Quando √© enviado uma mensagem, sempre √© recebido pelo **Leader**, dentro da mensagem √© pasado um parametro **Ack**.

-   **Ack=0**: O produtor n√£o recebe uma confirma√ß√£o do Kafka que a mensagem foi salva, entretanto, como o Kafka n√£o fica a todo tempo notifiando o produtor, se torna mais r√°pido o processamento de mensagens, √© importante estar ciente que ao perder mensagem, ela n√£o n√£o ir√° fazer falta.

<img src="./media/kafka/kafka-9-2.png" />

-   **Ack=1:**: O produtor recebe uma confirma√ß√£o do Kafka que a mensagem foi salva, entretanto se o broker A (Leader) cai e n√£o teve tempo h√°bil de replicar para os **Followers**, o produtor acredita que a mensagem foi salva, entretanto, a mensagem √© perdida.

<img src="./media/kafka/kafka-9-3.png" />

-   **Ack=-1:**: O produtor recebe uma confirma√ß√£o do Kafka que a mensagem foi salva pelo Leader, que por sua vez, replica as mensagens para os Followers, que por sua vez, notifica ao Leader que as mensagens foram salvas, que por sua vez, notifica ao produtor que a mensagem foi salva, essa √© a op√ß√£o mais segura, entretanto √© a mais custosa.

#### Melhor performance

<img src="./media/kafka/kafka-10-1.png" />

-   **At most once:** Quando as mensagens s√£o enviadas, pode ocorrer perdas de mensages nesse tipo de configura√ß√£o.

#### Performance moderada

<img src="./media/kafka/kafka-10-2.png" />

-   **At least once:** Quando as mensagens s√£o enviadas, pode haver duplica√ß√µes de mensagens, nesse caso h√° uma necessidade da aplica√ß√£o realizar o tratamento das duplica√ß√µes.

#### Pior performance

<img src="./media/kafka/kafka-10-3.png" />

-   **Exacly once:** Nesse tipo de configura√ß√£o o Kafka garante que n√£o vai ocorrer perdas e duplica√ß√µes.

### Indepot√™ncia do produtor

<img src="./media/kafka/kafka-11.png" />

-   **OFF:** O caso acima demonstrado, no envio 4, ocorre uma falha de comunica√ß√£o de rede e o produtor vai enviar a mensagem novamente, dessa forma, duplicando a mensagem.

-   **ON:** Quando configurado como indepot√™ncia on, o Kafka vai perceber o problema e n√£o vai enviar a mensagem novamente, dessa forma, descarta a mensagem e garante a ordem a sua ordem na fila.

## Consumers

<img src="./media/kafka/kafka-12-1.png" />

No caso demonstrado acima, temos um t√≥pico com 3 parti√ß√µes e um consumidor lendo das 3 parti√ß√µes, quando um consumidor n√£o est√° em um grupo, o Kafka considera que esse comsumidor √© o pr√≥prio grupo.

### Grupos de consumidores

<img src="./media/kafka/kafka-12-2.png" />

Como demonstrado acima, foi criado um grupo chamado de **Grupo X**, com 2 consumidores e o Kafka se encarrega de realizar a distribui√ß√£o das leituras.

**Observa√ß√£o:** Caso contenha um terceiro consumidor (c) sem estar dentro do Grupo X, ir√° ler das 3 parti√ß√µes.

<img src="./media/kafka/kafka-12-3.png" />

No caso acima, cada consumiror ler uma parti√ß√£o, esse √© o melhor caso.

<img src="./media/kafka/kafka-12-4.png" />

**Observa√ß√£o 1:** Caso contenha um quarto consumidor (d), n√£o vai poder ler nenhuma parti√ß√£o, como demonstrado na imagem acima.

**Observa√ß√£o 2:** N√£o h√° possibilidade de 2 consumidores em um mesmo grupo, ler a mesma parti√ß√£o.

## Kafka vs RabbitMQ

O Kafka n√£o trabalha igual ao RabbitMQ, ele salva as mensagens em disco, o RabbitMQ em mem√≥ria.

## Recomenda√ß√µes m√≠nimas

-   Um cluster com 3 brokers.

## Command line

### Subindo e acessando o container

```bash
# Subindo os containers
docker-compose up -d

# Acessando o container para criar o t√≥pico
docker exec -it customer-clean-architecture_kafka-1_1 bash
```

### T√≥picos

```bash
# Listando os t√≥picos existentes
kafka-topics --list --bootstrap-server localhost:29092

# Criando o t√≥pico
kafka-topics --create --bootstrap-server localhost:29092 --replication-factor 2 --partitions 2 --topic topic-customer

# Exibindo informa√ß√µes do t√≥pico, parti√ß√µes, l√≠deres e r√©plicas
kafka-topics --describe --bootstrap-server localhost:29092 --topic topic-customer

# Deletando um t√≥pico
kafka-topics --bootstrap-server localhost:29092 --delete --topic topic-customer
```

### Produtor

```bash
# Criando um produtor para um t√≥pico existente (topic-customer)
# Ap√≥s criar, digite as mensagens a serrem enviadas
# ctrl + c para sair
kafka-console-producer --broker-list localhost:29092 --topic topic-customer
```

### Consumidor

```bash
# Criando um consumidor para um t√≥pico existente (topic-customer)
# --from-beginning (pega as mensagens do in√≠cio do t√≥pico criado)
# ctrl + c para sair
kafka-console-consumer --bootstrap-server localhost:29092 --from-beginning --topic topic-customer

# Criando um consumidor para o t√≥pico existente com grupo
# ctrl + c para sair
kafka-console-consumer --bootstrap-server localhost:29092 --from-beginning --topic topic-customer --group group-clean
```

### Grupos

```bash
# Listar grupos
kafka-consumer-groups --bootstrap-server localhost:29092 --list

# Exibindo informa√ß√µes sobre os consumidores conetados, pati√ß√µes, offset e lag
kafka-consumer-groups --bootstrap-server localhost:29092 --group group-clean --describe
```

<hr />

<div>
  <img align="left" src="https://imgur.com/k8HFd0F.png" width=35 alt="Profile"/>
  <sub>Made with üíô by <a href="https://github.com/venzel">En√©as Almeida</a></sub>
</div>
